# -*- coding: utf-8 -*-
"""[KHUDA_CV]눈감지마 일정학습.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13SduVJSpNuc51SFMIhIIaFo_xOlt6osa
"""

from google.colab import drive
drive.mount('/content/drive')

import os
import zipfile
import pandas as pd
import torch
import torch.nn as nn
import torchvision.models as models
import torchvision.transforms as transforms
from torch.utils.data import Dataset, DataLoader
from PIL import Image
from sklearn.metrics import accuracy_score
import torch.optim as optim
from sklearn.model_selection import train_test_split

# 압축 해제 경로 (이미 파일이 존재하면 해제 과정 생략)
extracted_folder = '/content/celeba_images'
os.makedirs(extracted_folder, exist_ok=True)

# zip 파일 압축 해제
img_zip = '/content/drive/MyDrive/CV데이터/image/img_align_celeba.zip'
if not os.path.exists(os.path.join(extracted_folder, 'img_align_celeba')):
    with zipfile.ZipFile(img_zip, 'r') as zip_ref:
        zip_ref.extractall(extracted_folder)

# 라벨 파일 경로 설정
label_file = '/content/drive/MyDrive/CV데이터/list_attr_celeba.csv'

# 데이터셋을 학습용과 테스트용으로 분할
attr_df = pd.read_csv(label_file)
train_df, test_df = train_test_split(attr_df, test_size=0.2, random_state=42)

# 데이터셋 클래스 정의
class EyeStateDataset(Dataset):
    def __init__(self, root_dir, dataframe, transform=None):
        self.root_dir = root_dir
        self.dataframe = dataframe
        self.transform = transform

    def __len__(self):
        return len(self.dataframe)

    def __getitem__(self, idx):
        row = self.dataframe.iloc[idx]
        img_name = row['image_id']
        label = 0 if row['Eyeglasses'] == -1 else 1
        img_path = os.path.join(self.root_dir, 'img_align_celeba', img_name)

        image = Image.open(img_path).convert('RGB')

        if self.transform:
            image = self.transform(image)

        return image, label

# 데이터 변환 설정
transform = transforms.Compose([
    transforms.Resize((128, 128)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# 데이터셋 및 데이터로더 준비
train_dataset = EyeStateDataset(root_dir=extracted_folder, dataframe=train_df, transform=transform)
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
test_dataset = EyeStateDataset(root_dir=extracted_folder, dataframe=test_df, transform=transform)
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

# MobileNet 모델 정의
class EyeStateModel(nn.Module):
    def __init__(self):
        super(EyeStateModel, self).__init__()
        self.mobilenet = models.mobilenet_v2(weights='MobileNet_V2_Weights.DEFAULT')
        self.mobilenet.classifier[1] = nn.Linear(self.mobilenet.last_channel, 2)

    def forward(self, x):
        return self.mobilenet(x)

# 모델 초기화
device = 'cuda' if torch.cuda.is_available() else 'cpu'
model = EyeStateModel().to(device)

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)
num_epochs = 10
early_stopping_threshold = 0.02  # 성능 향상 최소 수치
best_accuracy = 0.0
batch_print_interval = 200  # 200 배치마다 출력

# 학습 루프
for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0
    correct = 0
    total = 0
    batch_count = 0

    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)

        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()
        batch_count += 1

        # 200배치마다 가중치 평균값, 손실, 정확도 출력
        if batch_count % batch_print_interval == 0:
            weight_avg = sum(p.mean().item() for p in model.parameters()) / len(list(model.parameters()))
            print(f"Batch {batch_count}: Weight Average: {weight_avg:.4f}, Loss: {running_loss / batch_count:.4f}, Accuracy: {correct / total:.4f}")

    epoch_accuracy = correct / total
    print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {running_loss/len(train_loader):.4f}, Accuracy: {epoch_accuracy:.4f}')

    # Early stopping 조건 확인
    if epoch_accuracy - best_accuracy > early_stopping_threshold:
        best_accuracy = epoch_accuracy  # 성능이 개선되면 최고 정확도 업데이트
    else:
        print("Early stopping due to lack of improvement.")
        break

# 테스트 정확도 평가
model.eval()
y_true = []
y_pred = []

with torch.no_grad():
    for images, labels in test_loader:
        images, labels = images.to(device), labels.to(device)
        outputs = model(images)
        _, preds = torch.max(outputs, 1)
        y_true.extend(labels.cpu().numpy())
        y_pred.extend(preds.cpu().numpy())

accuracy = accuracy_score(y_true, y_pred)
print(f"Final Test Accuracy: {accuracy:.4f}")

import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.metrics import accuracy_score

torch.save(model.state_dict(), 'eyeopen.pth')

