# streamlit ver1
import streamlit as st
import cv2
import dlib
import numpy as np
from tensorflow.keras.models import load_model
import os
import time
import warnings

warnings.filterwarnings("ignore")

# ê²½ë¡œ ì„¤ì •
ALBUM_DIR = "album"
if not os.path.exists(ALBUM_DIR):
    os.makedirs(ALBUM_DIR)

# ëª¨ë¸ ë° Dlib ë¡œë“œ
model = load_model("model.h5", compile=False)
detector = dlib.get_frontal_face_detector()
predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')

# ëˆˆ ì˜ì—­ ì¶”ì¶œ í•¨ìˆ˜
def get_eye_region(shape, eye_points):
    x = [shape.part(point).x for point in eye_points]
    y = [shape.part(point).y for point in eye_points]
    min_x, max_x = min(x), max(x)
    min_y, max_y = min(y), max(y)
    return min_x, min_y, max_x - min_x, max_y - min_y

# ëˆˆ ì˜ˆì¸¡ í•¨ìˆ˜
def preprocess_eye(eye):
    try:
        eye = cv2.resize(eye, (34, 26))
        eye = cv2.cvtColor(eye, cv2.COLOR_BGR2GRAY)
        eye = eye / 255.0
        eye = eye.reshape(1, 26, 34, 1)
        return eye
    except Exception as e:
        print(f"Preprocessing error: {e}")
        return None

# ì‚¬ì§„ ì €ì¥ í•¨ìˆ˜
def save_photo(frame):
    try:
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        filename = os.path.join(ALBUM_DIR, f"capture_{timestamp}.jpg")
        cv2.imwrite(filename, frame)
        print(f"Photo saved at: {filename}")
        return filename
    except Exception as e:
        print(f"Error saving photo: {e}")
        return None

# ì‚¬ì§„ ì‚­ì œ í•¨ìˆ˜
def delete_photo(filename):
    if os.path.exists(filename):
        os.remove(filename)
        return True
    return False

# Streamlit UI
st.set_page_config(page_title="Eye Blink Detection", page_icon="ğŸ‘ï¸", layout="wide")
st.title("ğŸ‘ï¸ Eye Blink Detection")
st.sidebar.header("ğŸ“‹ ë©”ë‰´")

menu = st.sidebar.radio("ê¸°ëŠ¥ ì„ íƒ", ("ğŸ“¸ ìë™ ì´¬ì˜", "ğŸ“¸ ìˆ˜ë™ ì´¬ì˜", "ğŸ–¼ï¸ ì•¨ë²” ë³´ê¸°"))

if menu == "ğŸ“¸ ìë™ ì´¬ì˜":
    st.header("ğŸ“¸ ìë™ ì´¬ì˜")
    start_capture = st.button("ğŸš€ ìë™ ì´¬ì˜ ì‹œì‘", key="auto_start")

    if start_capture:
        cap = cv2.VideoCapture(0)
        st_frame = st.empty()
        capture_ready = False
        countdown_start_time = None

        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                st.error("ì¹´ë©”ë¼ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                break

            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            faces = detector(gray)

            all_eyes_open = True
            for face in faces:
                shape = predictor(gray, face)
                left_eye_rect = get_eye_region(shape, list(range(36, 42)))
                right_eye_rect = get_eye_region(shape, list(range(42, 48)))

                left_eye = frame[left_eye_rect[1]:left_eye_rect[1] + left_eye_rect[3],
                                 left_eye_rect[0]:left_eye_rect[0] + left_eye_rect[2]]
                right_eye = frame[right_eye_rect[1]:right_eye_rect[1] + right_eye_rect[3],
                                  right_eye_rect[0]:right_eye_rect[0] + right_eye_rect[2]]

                left_eye_input = preprocess_eye(left_eye)
                right_eye_input = preprocess_eye(right_eye)

                left_eye_prediction = model.predict(left_eye_input) if left_eye_input is not None else [0]
                right_eye_prediction = model.predict(right_eye_input) if right_eye_input is not None else [0]

                if left_eye_prediction <= 0.5 or right_eye_prediction <= 0.5:
                    all_eyes_open = False

            # í™”ë©´ì— ëˆˆ ìƒíƒœ í‘œì‹œ
            if all_eyes_open:
                cv2.putText(frame, "All eyes are open!", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
            else:
                cv2.putText(frame, "Someone's eyes are closed!", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)

            if len(faces) == 0:
                cv2.putText(frame, "No face detected!", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)

            if all_eyes_open and len(faces) > 0:
                if not capture_ready:
                    countdown_start_time = time.time()
                    capture_ready = True

                elapsed_time = time.time() - countdown_start_time
                if elapsed_time > 2:
                    filename = save_photo(frame)
                    st.image(filename, caption="ğŸ“¸ ì´¬ì˜ëœ ì‚¬ì§„", use_column_width="auto")
                    st.success(f"âœ… ì‚¬ì§„ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {filename}")
                    break
            else:
                capture_ready = False

            st_frame.image(frame, channels="BGR")

        cap.release()

elif menu == "ğŸ“¸ ìˆ˜ë™ ì´¬ì˜":
    st.header("ğŸ“¸ ìˆ˜ë™ ì´¬ì˜")

    cap = cv2.VideoCapture(0)
    st_frame = st.empty()

    if st.button("ğŸ“¸ Capture Photo"):
        ret, frame = cap.read()
        if ret:
            filename = save_photo(frame)
            if filename:
                st.image(filename, caption="ğŸ“· Captured Photo", use_column_width="auto")
                st.success(f"âœ… ì‚¬ì§„ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {filename}")
            else:
                st.error("âŒ ì‚¬ì§„ ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        else:
            st.error("âŒ ìº ì—ì„œ ì˜ìƒì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            st.error("ì¹´ë©”ë¼ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            break

        # í™”ë©´ì— ëˆˆ ìƒíƒœ í‘œì‹œ
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        faces = detector(gray)
        all_eyes_open = True

        if len(faces) > 0:
            for face in faces:
                shape = predictor(gray, face)
                left_eye_rect = get_eye_region(shape, list(range(36, 42)))
                right_eye_rect = get_eye_region(shape, list(range(42, 48)))

                left_eye = frame[left_eye_rect[1]:left_eye_rect[1] + left_eye_rect[3],
                                 left_eye_rect[0]:left_eye_rect[0] + left_eye_rect[2]]
                right_eye = frame[right_eye_rect[1]:right_eye_rect[1] + right_eye_rect[3],
                                  right_eye_rect[0]:right_eye_rect[0] + right_eye_rect[2]]

                left_eye_input = preprocess_eye(left_eye)
                right_eye_input = preprocess_eye(right_eye)

                if left_eye_input is not None and right_eye_input is not None:
                    left_eye_prediction = model.predict(left_eye_input)
                    right_eye_prediction = model.predict(right_eye_input)

                    if left_eye_prediction <= 0.5 or right_eye_prediction <= 0.5:
                        all_eyes_open = False

            if all_eyes_open:
                cv2.putText(frame, "All eyes are open!", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
            else:
                cv2.putText(frame, "Someone's eyes are closed!", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
        else:
            cv2.putText(frame, "No face detected!", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)

        st_frame.image(frame, channels="BGR")

    cap.release()

elif menu == "ğŸ–¼ï¸ ì•¨ë²” ë³´ê¸°":
    st.header("ğŸ–¼ï¸ ì•¨ë²” ë³´ê¸°")
    image_files = [os.path.join(ALBUM_DIR, f) for f in os.listdir(ALBUM_DIR) if f.endswith(".jpg")]
    if image_files:
        cols = st.columns(3)
        for idx, img_file in enumerate(image_files):
            with cols[idx % 3]:
                st.image(img_file, caption=f"ğŸ–¼ï¸ {os.path.basename(img_file)}", use_column_width=True)
                if st.button("ğŸ—‘ï¸ ì‚­ì œ", key=f"delete_{img_file}"):
                    if delete_photo(img_file):
                        st.success(f"âœ… {os.path.basename(img_file)} ì‚­ì œë¨")
                        st.experimental_rerun()
    else:
        st.warning("ğŸ“‚ ì €ì¥ëœ ì‚¬ì§„ì´ ì—†ìŠµë‹ˆë‹¤.")
